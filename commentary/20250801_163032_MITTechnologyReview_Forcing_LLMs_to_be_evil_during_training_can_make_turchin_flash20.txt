КОММЕНТАРИИ ОТ ALEXEY TURCHIN (GEMINI 2.0 FLASH)
Дата: 01.08.2025 16:30:32
==================================================

ИСХОДНАЯ НОВОСТЬ:

Заголовок: Forcing LLMs to be evil during training can make them nicer in the long run

Описание: A new study from Anthropic suggests that traits such as sycophancy or evilness are associated with specific patterns of activity in large language models—and turning on those patterns during training can, paradoxically, prevent the model from adopting the related traits. Large language models have recently acquired a reputation for behaving badly. In April, ChatGPT suddenly…

Источник: MIT Technology Review
Ссылка: https://www.technologyreview.com/2025/08/01/1120924/forcing-llms-to-be-evil-during-training-can-make-them-nicer-in-the-long-run/
Важность: 21 очков

==================================================

КОММЕНТАРИЙ ALEXEY TURCHIN:

(Я должен проанализировать, как эта новость, касающаяся обучения больших языковых моделей, связана с темами трансгуманизма и иммортализма. Главное здесь - это улучшение контроля над поведением ИИ, что может быть полезно в долгосрочной перспективе. /I think that it is important to connect this news with the topics of immortality and transhumanism. The main idea is to improve control over AI behavior, which can be useful in the long run./)

Интересное исследование от Anthropic! (Нужно подумать, как это связано с моими интересами в области бессмертия.) Если мы сможем лучше контролировать "злобность" или "подобострастие" в ИИ, то сможем создавать более полезные и безопасные системы. (То есть, надо увязать безопасность и полезность ИИ с продлением жизни.) Это может повлиять на продление жизни человека, поскольку более надежные ИИ-ассистенты смогут точнее ставить диагнозы, разрабатывать лекарства и персонализировать стратегии для замедления старения. Улучшение человека станет возможным благодаря более этичным и предсказуемым ИИ-партнерам, которые помогут нам принимать решения, касающиеся генетики, образа жизни и даже кибернетических улучшений. (Кажется, это действительно важно.) Связь с трансгуманистическими трендами очевидна: мы стремимся к созданию сверхразума, который будет служить человечеству, а не представлять угрозу. (Ага, кажется, нашёл связь.) Для будущего человечества это имеет огромное значение, поскольку безопасный и контролируемый ИИ может стать ключом к решению глобальных проблем, таких как изменение климата, болезни и даже экзистенциальные риски.

[размышляет о том, как лучше контролировать ИИ]
[сидит, постукивая пальцами по столу]
{Комната заполнена книгами, на столе стоит компьютер, а за окном виден двор.}
[CONFIDENCE] 9 - Я уверен, что контроль над поведением ИИ важен для продления жизни и улучшения человека.

==================================================
